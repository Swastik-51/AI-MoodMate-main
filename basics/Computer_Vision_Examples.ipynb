{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4e373e3",
   "metadata": {},
   "source": [
    "# Computer Vision with OpenCV\n",
    "\n",
    "This notebook contains comprehensive examples of computer vision techniques using OpenCV. The examples progress from basic camera operations to advanced image processing and computer vision algorithms.\n",
    "\n",
    "## Prerequisites\n",
    "```bash\n",
    "pip install opencv-python numpy\n",
    "```\n",
    "\n",
    "## Table of Contents\n",
    "1. [Basic Camera Operations](#camera)\n",
    "2. [Image Transformations](#transformations)\n",
    "3. [Image Filtering and Effects](#filtering)\n",
    "4. [Image Analysis Techniques](#analysis)\n",
    "5. [Advanced Computer Vision](#advanced)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed71b5a6",
   "metadata": {},
   "source": [
    "## 1. Basic Camera Operations <a id=\"camera\"></a>\n",
    "\n",
    "### Real-time Camera Stream Capture\n",
    "This example demonstrates how to capture and display live video from your webcam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd6082be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# For USB webcam (index 0 = first camera)\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# For IP camera (replace with your IP stream URL)\n",
    "# cap = cv2.VideoCapture(\"rtsp://username:password@ip:554/stream\")\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    cv2.imshow(\"Camera Stream\", frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25fdd373",
   "metadata": {},
   "source": [
    "### Frame Extraction and Saving\n",
    "Capture individual frames from the video stream and save them to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d430bd0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CODE 2\n",
    "\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Create output folder\n",
    "os.makedirs(\"frames\", exist_ok=True)\n",
    "frame_count = 0\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Show stream\n",
    "    cv2.imshow(\"Camera Stream\", frame)\n",
    "\n",
    "    # Save frame\n",
    "    filename = f\"frames/frame_{frame_count:06d}.jpg\"\n",
    "    cv2.imwrite(filename, frame)\n",
    "    frame_count += 1\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6802dc7",
   "metadata": {},
   "source": [
    "### Basic Image Loading and Display\n",
    "Load a static image from disk and display it in a window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d83cb280",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CODE 3\n",
    "\n",
    "import cv2\n",
    "\n",
    "# Read an image\n",
    "img = cv2.imread(\"resources/man.jpg\")  # Using sample image from resources folder\\n\",\n",
    "\n",
    "# Check if image loaded successfully\n",
    "if img is None:\n",
    "    print(\"Error: Could not read image.\")\n",
    "else:\n",
    "    # Show the image in a window\n",
    "    cv2.imshow(\"My Image\", img)\n",
    "\n",
    "    # Wait until a key is pressed, then close\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6a0a712",
   "metadata": {},
   "source": [
    "## 2. Image Transformations <a id=\"transformations\"></a>\n",
    "\n",
    "### Image Flipping Operations\n",
    "Demonstrate different ways to flip images (vertical, horizontal, both)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a27904",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CODE 4\n",
    "\n",
    "import cv2\n",
    "\n",
    "# Read image\n",
    "img = cv2.imread(\"resources/man.jpg\")  # Using sample image from resources folder\n",
    "\n",
    "if img is None:\n",
    "    print(\"Error: Could not read image.\")\n",
    "else:\n",
    "    # Flip vertically (0), horizontally (1), or both (-1)\n",
    "    flip_vertical = cv2.flip(img, 0)\n",
    "    flip_horizontal = cv2.flip(img, 1)\n",
    "    flip_both = cv2.flip(img, -1)\n",
    "\n",
    "    # Display images\n",
    "    cv2.imshow(\"Original\", img)\n",
    "    cv2.imshow(\"Flipped Vertically\", flip_vertical)\n",
    "    cv2.imshow(\"Flipped Horizontally\", flip_horizontal)\n",
    "    cv2.imshow(\"Flipped Both\", flip_both)\n",
    "\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1348b19",
   "metadata": {},
   "source": [
    "### Image Resizing\n",
    "Resize images to specific dimensions while maintaining or changing aspect ratios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f649c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CODE 5 \n",
    "\n",
    "import cv2\n",
    "\n",
    "# Load an image\n",
    "img = cv2.imread(\"resources/man.jpg\")   # Using sample image from resources folder\n",
    "\n",
    "# Check if the image loaded correctly\n",
    "if img is None:\n",
    "    print(\"Error: Could not read image.\")\n",
    "    exit()\n",
    "\n",
    "# Resize image (width=300, height=300)\n",
    "resized = cv2.resize(img, (300, 300))\n",
    "\n",
    "# Show both\n",
    "cv2.imshow(\"Original\", img)\n",
    "cv2.imshow(\"Resized\", resized)\n",
    "\n",
    "# Save the resized image\n",
    "cv2.imwrite(\"resized_output.jpg\", resized)\n",
    "\n",
    "# Wait for a key press and close windows\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab36d10",
   "metadata": {},
   "source": [
    "### Color Space Conversion (RGB to Grayscale)\n",
    "Convert color images to grayscale for preprocessing or analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10603ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CODE 6\n",
    "\n",
    "import cv2\n",
    "\n",
    "# Load an image\n",
    "img = cv2.imread(\"resources/man.jpg\")   # Using sample image from resources folder\n",
    "\n",
    "# Check if image loaded correctly\n",
    "if img is None:\n",
    "    print(\"Error: Could not read image.\")\n",
    "    exit()\n",
    "\n",
    "# Convert to grayscale\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Show both\n",
    "cv2.imshow(\"Original\", img)\n",
    "cv2.imshow(\"Grayscale\", gray)\n",
    "\n",
    "# Save the grayscale image\n",
    "cv2.imwrite(\"grayscale_output.jpg\", gray)\n",
    "\n",
    "# Wait for a key press and close windows\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8196852",
   "metadata": {},
   "source": [
    "## 3. Image Filtering and Effects <a id=\"filtering\"></a>\n",
    "\n",
    "### Gaussian Blur Filter\n",
    "Apply blur effects to reduce noise and smooth images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "633eab39",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CODE 7\n",
    "\n",
    "import cv2\n",
    "\n",
    "# Load an image\n",
    "img = cv2.imread(\"resources/man.jpg\")   # Using sample image from resources folder\n",
    "\n",
    "# Check if image loaded correctly\n",
    "if img is None:\n",
    "    print(\"Error: Could not read image.\")\n",
    "    exit()\n",
    "\n",
    "# Apply Gaussian Blur (15x15 kernel)\n",
    "blur = cv2.GaussianBlur(img, (15, 15), 0)\n",
    "\n",
    "# Show both\n",
    "cv2.imshow(\"Original\", img)\n",
    "cv2.imshow(\"Blurred\", blur)\n",
    "\n",
    "# Save the blurred image\n",
    "cv2.imwrite(\"blurred_output.jpg\", blur)\n",
    "\n",
    "# Wait for a key press and close windows\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "616f1758",
   "metadata": {},
   "source": [
    "### Drawing Shapes and Text\n",
    "Create graphics programmatically using OpenCV drawing functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74687f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CODE 8\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = np.zeros((500, 500, 3), dtype=\"uint8\")\n",
    "\n",
    "# Draw shapes\n",
    "cv2.line(img, (0, 0), (500, 500), (255, 0, 0), 5)\n",
    "cv2.rectangle(img, (50, 50), (200, 200), (0, 255, 0), 3)\n",
    "cv2.circle(img, (300, 300), 80, (0, 0, 255), -1)\n",
    "\n",
    "# Add text\n",
    "cv2.putText(img, \"OpenCV Demo\", (50, 400), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
    "\n",
    "cv2.imshow(\"Shapes and Text\", img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed54e87",
   "metadata": {},
   "source": [
    "## 4. Image Analysis Techniques <a id=\"analysis\"></a>\n",
    "\n",
    "### Binary Thresholding\n",
    "Convert grayscale images to binary (black and white) for segmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3424074a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CODE 9\n",
    "\n",
    "import cv2\n",
    "\n",
    "img = cv2.imread(\"resources/man.jpg\", 0)  # Load sample image in grayscale\n",
    "\n",
    "_, thresh = cv2.threshold(img, 127, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "cv2.imshow(\"Original\", img)\n",
    "cv2.imshow(\"Thresholded\", thresh)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "994e2a8f",
   "metadata": {},
   "source": [
    "### Edge Detection using Canny Algorithm\n",
    "Detect edges in images using the Canny edge detection algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4549710d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CODE 10\n",
    "\n",
    "import cv2\n",
    "\n",
    "img = cv2.imread(\"resources/man.jpg\", 0)  # Using sample image from resources folder\n",
    "\n",
    "edges = cv2.Canny(img, 100, 200)\n",
    "\n",
    "cv2.imshow(\"Edges\", edges)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "097e2063",
   "metadata": {},
   "source": [
    "## 5. Advanced Computer Vision <a id=\"advanced\"></a>\n",
    "\n",
    "### Face Detection using Haar Cascades\n",
    "Detect human faces in images using pre-trained Haar cascade classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feec17fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CODE 11\n",
    "\n",
    "import cv2\n",
    "\n",
    "# Load pre-trained classifier\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\")\n",
    "\n",
    "img = cv2.imread(\"resources/mountainous.jpg\")  # Using sample image from resources folder\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "faces = face_cascade.detectMultiScale(gray, 1.1, 4)\n",
    "\n",
    "for (x, y, w, h) in faces:\n",
    "    cv2.rectangle(img, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "\n",
    "cv2.imshow(\"Face Detection\", img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f75bcba0",
   "metadata": {},
   "source": [
    "### Contour Detection and Analysis\n",
    "Find and draw contours (object boundaries) in images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c4694c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CODE 12\n",
    "\n",
    "import cv2\n",
    "\n",
    "img = cv2.imread(\"resources/man.jpg\")  # Using sample image from resources folder\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Threshold\n",
    "_, thresh = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "# Find contours\n",
    "contours, _ = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# Draw contours\n",
    "cv2.drawContours(img, contours, -1, (0, 255, 0), 2)\n",
    "\n",
    "cv2.imshow(\"Contours\", img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f8604ad",
   "metadata": {},
   "source": [
    "### Color-Based Object Tracking\n",
    "Track objects based on their color in HSV color space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec4328b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CODE 13\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread(\"resources/man.jpg\")  # Using sample image from resources folder\n",
    "hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "# Define range for blue color\n",
    "lower_blue = np.array([100, 150, 0])\n",
    "upper_blue = np.array([140, 255, 255])\n",
    "\n",
    "mask = cv2.inRange(hsv, lower_blue, upper_blue)\n",
    "result = cv2.bitwise_and(img, img, mask=mask)\n",
    "\n",
    "cv2.imshow(\"Original\", img)\n",
    "cv2.imshow(\"Color Mask\", mask)\n",
    "cv2.imshow(\"Result\", result)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "398d5d40",
   "metadata": {},
   "source": [
    "### GrabCut Foreground Extraction\n",
    "Advanced foreground/background segmentation using the GrabCut algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "498ed50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CODE 14\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread(\"resources/man.jpg\")  # Using sample image from resources folder\n",
    "mask = np.zeros(img.shape[:2], np.uint8)\n",
    "\n",
    "bgdModel = np.zeros((1, 65), np.float64)\n",
    "fgdModel = np.zeros((1, 65), np.float64)\n",
    "\n",
    "# Define rectangle around the object (adjust coordinates for your image)\n",
    "rect = (50, 50, 450, 290)\n",
    "cv2.grabCut(img, mask, rect, bgdModel, fgdModel, 5, cv2.GC_INIT_WITH_RECT)\n",
    "\n",
    "# Modify the mask to get foreground\n",
    "mask2 = np.where((mask == 2) | (mask == 0), 0, 1).astype('uint8')\n",
    "result = img * mask2[:, :, np.newaxis]\n",
    "\n",
    "cv2.imshow(\"Original\", img)\n",
    "cv2.imshow(\"GrabCut Result\", result)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75a14a72",
   "metadata": {},
   "source": [
    "### Real-Time Color Tracking\n",
    "Track colored objects in real-time video stream."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64267f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CODE 15\n",
    "\n",
    "import cv2\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # Blue color range\n",
    "    lower_blue = (100, 150, 0)\n",
    "    upper_blue = (140, 255, 255)\n",
    "\n",
    "    mask = cv2.inRange(hsv, lower_blue, upper_blue)\n",
    "    result = cv2.bitwise_and(frame, frame, mask=mask)\n",
    "\n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "    cv2.imshow(\"Mask\", mask)\n",
    "    cv2.imshow(\"Tracked\", result)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16550002",
   "metadata": {},
   "source": [
    "### Morphological Operations\n",
    "Apply erosion and dilation operations for noise removal and shape analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e013b671",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CODE 16\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread(\"resources/man.jpg\", 0)  # Using sample image from resources folder\n",
    "\n",
    "_, thresh = cv2.threshold(img, 127, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "kernel = np.ones((5, 5), np.uint8)\n",
    "\n",
    "erosion = cv2.erode(thresh, kernel, iterations=1)\n",
    "dilation = cv2.dilate(thresh, kernel, iterations=1)\n",
    "\n",
    "cv2.imshow(\"Original\", img)\n",
    "cv2.imshow(\"Erosion\", erosion)\n",
    "cv2.imshow(\"Dilation\", dilation)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a5075e",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook covered a comprehensive range of computer vision techniques:\n",
    "\n",
    "- **Basic Operations**: Camera capture, image loading, and display\n",
    "- **Transformations**: Flipping, resizing, and color space conversion\n",
    "- **Filtering**: Blur effects and noise reduction\n",
    "- **Analysis**: Thresholding, edge detection, and contour finding\n",
    "- **Advanced Techniques**: Face detection, color tracking, and morphological operations\n",
    "\n",
    "Each example builds upon previous concepts, providing a solid foundation for computer vision projects. Remember to adjust image paths and camera indices according to your system setup.\n",
    "\n",
    "### Next Steps\n",
    "- Experiment with different parameters in each function\n",
    "- Combine multiple techniques for complex image processing pipelines\n",
    "- Explore machine learning-based computer vision with libraries like TensorFlow or PyTorch"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
